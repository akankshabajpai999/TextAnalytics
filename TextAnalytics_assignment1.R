rm(list=ls(spase))
wiki = read.csv("wiki.csv", stringsAsFactors=FALSE)
table(wiki$Vandal)
install.packages("tm")
library(tm)
install.packages("SnowballC")
library(SnowballC)
corpusAdded = Corpus(VectorSource(wiki$Added))
corpusAdded[[1]]        
corpusAdded = tm_map(corpusAdded,tolower)
corpusAdded = tm_map(corpusAdded,removePunctuation)
corpusAdded = tm_map(corpusAdded,removeWords,stopwords("english"))
corpusAdded = tm_map(corpusAdded,stemDocument)
freq = DocumentTermMatrix(corpusAdded)
length(stopwords("english"))
spaseAdded = removeSparseTerms(freq,0.997)
wordsAdded = as.data.frame(as.matrix(spaseAdded))
colnames(wordsAdded) = paste("A", colnames(wordsAdded))
corpusRemoved = Corpus(VectorSource(wiki$Removed))
corpusRemoved = tm_map(corpusRemoved, tolower)
corpusRemoved = tm_map(corpusRemoved, removePunctuation)
corpusRemoved = tm_map(corpusRemoved, removeWords,stopwords("english"))
corpusRemoved = tm_map(corpusRemoved, stemDocument)
freq2 = DocumentTermMatrix(corpusRemoved)
sparseRemoved = removeSparseTerms(freq2,0.997)
wordsRemoved = as.data.frame(as.matrix(sparseRemoved))
colnames(wordsRemoved) = paste("R", colnames(wordsRemoved))
str(wordsRemoved)
wikiWords = cbind(wordsAdded, wordsRemoved)
wikiWords$Vandal = wiki$Vandal
set.seed(123)
split = sample.split(wikiWords$Vandal,SplitRatio = 0.7)
train = subset(wikiWords,split==TRUE)
test = subset(wikiWords,split==FALSE)
table(test$Vandal)
618/nrow(test)
wordCart = rpart(Vandal~.,data=train,method = "class")
pred = predict(wordCart,newdata = test,type="class")
table(test$Vandal,pred)
(614+19)/nrow(test)
prp(wordCart)
wikiWords2 = wikiWords
wikiWords2$HTTP = ifelse(grepl("http",wiki$Added,fixed = TRUE),1,0) 
table(wikiWords2$HTTP)
217/nrow(wikiWords2)
wikiTrain2= subset(wikiWords2,split==TRUE)
wikiTest2 = subset(wikiWords2,split==FALSE)
wikiCart2 = rpart(Vandal~.,data=wikiTrain2,method = "class")
pred2 = predict(wikiCart2,newdata=wikiTest2,type="class")
table(wikiTest2$Vandal,pred2)
(1109+2)/(1109+52+2)
wikiWords2$NumWordsAdded = rowSums(as.matrix(freq))
wikiWords2$NumWordsRemoved = rowSums(as.matrix(freq2))
mean(wikiWords2$NumWordsAdded)
wikiTrain3= subset(wikiWords2,split==TRUE)
wikiTest3 = subset(wikiWords2,split==FALSE)
wikiCart3 = rpart(Vandal~.,data=wikiTrain3,method = "class")
pred3 = predict(wikiCart3,newdata = wikiTest3,type = "class")
table(wikiTest3$Vandal,pred3)
(514+248)/nrow(wikiTest3)
wikiWords3=wikiWords2
wikiWords3$Minor = wiki$Minor
wikiWords3$Loggedin = wiki$Loggedin
Train3 = subset(wikiWords3,split==TRUE)
Test3 = subset(wikiWords3,split==FALSE)
Cart3 = rpart(Vandal~.,data=Train3,method="class")
predi3 = predict(Cart3,newdata = Test3,type = "class")
table(Test3$Vandal,predi3)
(595+241)/nrow(Test3)
prp(Cart3)
